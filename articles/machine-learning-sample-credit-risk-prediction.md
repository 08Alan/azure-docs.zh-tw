<properties title="Azure Machine Learning Sample: Credit risk prediction" pageTitle="Machine Learning 範例：信用風險預測 | Azure" description="A sample Azure Machine Learning experiment to develop a binary classification model that predicts if an applicant is a low credit risk or a high credit risk." metaKeywords="" services="machine-learning" solutions="" documentationCenter="" authors="garye" manager="paulettm" editor="cgronlun"  videoId="" scriptId="" />

<tags ms.service="machine-learning" ms.workload="data-services" ms.tgt_pltfrm="na" ms.devlang="na" ms.topic="article" ms.date="10/23/2014" ms.author="garye" />


# Azure Machine Learning 範例：信用風險預測 

>[AZURE.NOTE]
>在 ML Studio 中可取得與此模型相關聯的[範例實驗]和[範例資料集]。如需詳細資訊，請參閱下列各項。
[範例實驗]: #sample-experiment
[範例資料集]: #sample-dataset

*如需如何建立及使用此實驗之簡化版的詳細逐步解說，請參閱[使用 Azure Machine Learning 開發預測方案](http://azure.microsoft.com/zh-tw/documentation/articles/machine-learning-walkthrough-develop-predictive-solution/)。*

此實驗的目的是要根據給定的信用申請資訊進行信用風險預測。預測是二進位值：低風險或高風險。 


<!-- Removed until the Training and Scoring parts are fixed
This example is divided into 3 sample experiments:

- Development Experiment â€" for experimenting with different models
- Training Experiment â€" to train the one chosen model
- Scoring Experiment â€" to set up a web service using the trained model
-->

<!-- Removed because we added a section at the bottom describing the dataset
##Dataset Description

The experiment uses the UCI Statlog (German Credit Card) dataset which can be found here: 
<a href="http://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)">http://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)</a>. 
我們目前使用來自這個網站的 german.data 檔案。

此資料集會將申請者 (以一組屬性說明) 分類為低或高信用風險。每個範例代表一名申請者。共有 20 項特性 (包括數值和類別) 以及一個二進位標籤 (信用風險值)。高信用風險項目有標籤 = 2，低信用風險項目有標籤 = 1。將低風險範例錯誤分類為高風險的成本為 1，而將高風險範例錯誤分類為低風險的成本是 5。
-->

##開發實驗

原始資料集具有以空格分隔的格式。我們將資料集轉換為 CSV 格式，並將其上傳至 ML Studio 中。這項轉換可使用 Powershell 來完成： 

	cat dataset.txt | %{$_ -replace " ",","} | sc german.csv

或者，也可以使用 Unix sed 命令：

	sed 's/ /,/g' german.data > german.csv

首先，我們使用 [**中繼資料編輯器**] 新增資料行名稱，以將資料集的預設資料行名稱取代為取自 UCI 網站上的資料集說明、而較具意義的名稱。新的資料行名稱會出現在 [**中繼資料編輯器**] 的 [**新資料行名稱**] 欄位中，並以逗號分隔。

接著，我們產生將用來開發風險預測模型的訓練集和測試集。我們使用將 [**Ratio of first output rows to input**] 設為 0.5 的 [**分割**] 模組，將原始資料集分割為大小相同的訓練集和測試集。
 
相較於將低風險誤判為高風險的成本，將高風險範例誤判為低風險的成本是其 5 倍之多，因此我們產生了反映此成本函數的新資料集。在此新資料集中，每個高風險範例都會複寫 5 次，而低風險範例則維持原狀。訓練和測試資料集的分割會在此複寫之前完成，以防止相同的範例同時出現在訓練集和測試集中。 

此複寫可透過下列以 [**執行 R 指令碼**] 模組執行的 R 程式碼來完成：

	dataset1 <- maml.mapInputPort(1)
	data.set<-dataset1[dataset1[,21]==1,]
	pos<-dataset1[dataset1[,21]==2,]
	for (i in 1:5) data.set<-rbind(data.set,pos)
	maml.mapOutputPort("data.set")

在我們的實驗中，我們會比較兩種產生模型的方法：訓練原始資料集和訓練複寫的資料集。在這兩種方法中，為了精準處理成本函數，我們會以複寫的測試集進行測試。分割和複寫的最終工作流程說明如下。在此工作流程中，[**分割**] 模組的左側輸出是訓練集，右側輸出則是測試集。請注意，後續在使用訓練集時會分成採用和不採用 [**執行 R 指令碼**] 兩種 - 也就是執行複寫和不執行複寫。

![Splitting training and test data][screen1]
 
除了查看訓練集中各範例的複寫有何效果以外，我們也會比較兩種演算法的效能：支援向量機器 (SVM) 和促進式決策樹 (boosted decision tree)。如此，我們可以有效產生 4 種模型：

- 以原始資料訓練的 SVM
- 以複寫資料訓練的 SVM
- 以原始資料訓練的促進式決策樹
- 以複寫資料訓練的促進式決策樹

「強化的決策樹」適合處理任何類型的特性。但由於 SVM 模組會產生線性分類器，因此它所產生的模型在所有特性皆具有相同的縮放比例時將會有最佳測試誤差。若要將所有特性轉換為相同的縮放比例，我們必須搭配使用 [**Transform Data by Scaling**] 模組和 tanh 轉換。此轉換會將所有數值特性轉換為 [0,1] 範圍。請注意，字串特性會由 SVM 模組轉換為類別特性，再轉換為二進位 0/1 特性，因此我們無須手動轉換字串特性。 

我們先使用 [**Two-Class Support Vector Machine**] 模組或 [**Two-Class Boosted Decision Tree**] 模組初始化學習演算法，然後使用 [**訓練模型**] 模組建立實際模型。[**評分模型**] 模組會使用這些模型產生測試範例的評分。以下說明結合這些模組並使用 SVM 和複寫訓練集的範例工作流程。請注意，[**訓練模型**] 會連接到訓練集，而 [**評分模型**] 則連接到測試集。

![Training and scoring a model][screen2]

在實驗的評估階段中，我們會分別計算前述 4 種模型的精確性。為此，我們將使用 [**評估模型**] 模組。請注意，此模組只能計算所有範例皆具有相同誤判成本時的精確性。但由於我們先前所複寫的是正範例，[**評估模型**] 所計算的精確性具有成本敏感性，其計算方式為  

![Accuracy computation][formula]

其中 *n+* 和 *n-* 是原始資料集中的正範例和負範例數目，而 *e+* 和 *e-* 是原始資料集中誤判的正範例和負範例數目。

[**評估模型**] 模組會比較 2 個評分模型，因此我們使用一個 [**評估模型**] 模組來比較 2 個 SVM 模型，並以另一個模組比較 2 個促進式決策樹模型。我們會將其整合成一份資料表，以完整檢視這 4 項結果。[**評估模型**] 會產生以單一資料列包含不同度量的資料表。我們可使用 [**新增資料列**] 模組，將所有結果整合成單一資料表。接著，我們使用 [**執行 R 指令碼**] 模組中的 R 指令碼，以 4 個模組的精確性在資料表中加註，在其中，我們會手動輸入最後一個資料表的資料列名稱。後，我們使用 ]**專案資料行**] 模組移除具有非相關度量的資料行。 

實驗的最終結果可在您以滑鼠右鍵按一下 [**專案資料行]**] 的 [**結果資料集**] 輸出後取得，如下所示：

![Results][results] 

其中，第一個資料行是用來產生模型的機器學習演算法的名稱，第二個資料行指出訓練集的類型，第三個資料行是成本敏感精確性。在此實驗中，SVM 模型會與複寫的訓練資料集搭配運作，而提供最佳精確性。

<!-- Removed until the Training and Scoring parts are fixed
##Training Experiment

The sample training experiment is a simplified version of the larger experiment using just the chosen SVM training model. 

Notice that unlike the development experiment, in the training experiment we chose to load the dataset from Azure blob storage using the **Reader** module. Having the dataset stored in Azure is very common when it is generated by other programs. By reading the dataset directly from Azure we skip the step of manually uploading the dataset into ML Studio. The parameters of the **Reader** module are shown below. In this example, the storage account name is â€œdatascienceâ€ and the dataset file â€œgerman.csvâ€ is placed in container â€œsampleexperimentsâ€. The account key is an access key of an Azure storage account. This key can be retrieved from your account in the Azure management portal.

![Azure storage parameters][screen3] 

##Scoring Experiment

The purpose of the sample scoring experiment is to set up a REST API web service that will score test examples. The trained model in this experiment (â€œCredit Risk modelâ€) was created from the training experiment by right-clicking the Train Model module and selecting **Save as Trained Model**. In this scoring experiment we load test examples, normalize them, and perform scoring using this saved trained model. 

After running this experiment and verifying that it generates the right scores we prepare to publish it as a web service by defining the service input and output. We define the web service input as the input port to the **Transform Data By Scaling** module by right-clicking the port and selecting **Set as Publish Input**. The web service output is set to the output of the **Score Model** module by right-clicking the output of **Score Model** and selecting **Set as Publish Output**. 

After setting up the service input and output we need to rerun the experiment and then click **Publish Web Service**. This publishes the web service to the staging environment and takes us to the ML Studio **WEB SERVICES** page. Here we can configure and test the service with sample data.

When the service is ready to go live, go to the **CONFIGURATION** tab on the **WEB SERVICES** page and click **READY FOR PRODUCTION?**. A request will be sent to the IT administrator for Machine Learning who can promote the service to the production environment.

![Web service ready for production][screen4] 
-->

## 範例實驗

在 ML Studio 中可取得與此模型相關聯的下列範例實驗：[**範例**] 索引標籤之下的 [**實驗**] 區段。

> **範例實驗 - 德國信用 - 開發**


## 範例資料集

在 ML Studio 中可取得此實驗所使用的下列範例資料集：[**儲存的資料集**] 之下的模組調色板。

###德國信用卡 UCI 資料集
[AZURE.INCLUDE [machine-learning-sample-dataset-german-credit-card-uci-dataset](../includes/machine-learning-sample-dataset-german-credit-card-uci-dataset.md)]



[screen1]:./media/machine-learning-sample-credit-risk-prediction/screen1.jpg
[screen2]:./media/machine-learning-sample-credit-risk-prediction/screen2.jpg
[formula]:./media/machine-learning-sample-credit-risk-prediction/formula.jpg
[results]:./media/machine-learning-sample-credit-risk-prediction/results.jpg
[screen3]:./media/machine-learning-sample-credit-risk-prediction/screen3.jpg
[screen4]:./media/machine-learning-sample-credit-risk-prediction/screen4.jpg
